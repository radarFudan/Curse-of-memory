2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_setup.py:_flush():76] Current SDK version is 0.15.9
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_setup.py:_flush():76] Configure stats pid to 1460736
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_setup.py:_flush():76] Loading settings from /home/shida/.config/wandb/settings
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_setup.py:_flush():76] Loading settings from /home/shida/Figure_1/wandb/settings
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'src/train.py', 'program': '/home/shida/Figure_1/src/train.py'}
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_init.py:_log_setup():524] Logging user logs to /home/shida/Figure_1/logs/LF_tanh_ssm_pol/runs/20230904/214859/wandb/run-20230904_214901-li5gxo2h/logs/debug.log
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_init.py:_log_setup():525] Logging internal logs to /home/shida/Figure_1/logs/LF_tanh_ssm_pol/runs/20230904/214859/wandb/run-20230904_214901-li5gxo2h/logs/debug-internal.log
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_init.py:init():564] calling init triggers
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {}
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_init.py:init():613] starting backend
2023-09-04 21:49:01,087 INFO    MainThread:1460736 [wandb_init.py:init():617] setting up manager
2023-09-04 21:49:01,088 INFO    MainThread:1460736 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-09-04 21:49:01,089 INFO    MainThread:1460736 [wandb_init.py:init():623] backend started and connected
2023-09-04 21:49:01,091 INFO    MainThread:1460736 [wandb_init.py:init():714] updated telemetry
2023-09-04 21:49:01,113 INFO    MainThread:1460736 [wandb_init.py:init():747] communicating run to backend with 60.0 second timeout
2023-09-04 21:49:02,001 INFO    MainThread:1460736 [wandb_run.py:_on_init():2180] communicating current version
2023-09-04 21:49:02,109 INFO    MainThread:1460736 [wandb_run.py:_on_init():2189] got version response 
2023-09-04 21:49:02,109 INFO    MainThread:1460736 [wandb_init.py:init():798] starting run threads in backend
2023-09-04 21:49:05,791 INFO    MainThread:1460736 [wandb_run.py:_console_start():2159] atexit reg
2023-09-04 21:49:05,791 INFO    MainThread:1460736 [wandb_run.py:_redirect():2014] redirect: wrap_raw
2023-09-04 21:49:05,791 INFO    MainThread:1460736 [wandb_run.py:_redirect():2079] Wrapping output streams.
2023-09-04 21:49:05,792 INFO    MainThread:1460736 [wandb_run.py:_redirect():2104] Redirects installed.
2023-09-04 21:49:05,793 INFO    MainThread:1460736 [wandb_init.py:init():839] run started, returning control to user process
2023-09-04 21:49:05,906 INFO    MainThread:1460736 [wandb_run.py:_config_callback():1282] config_cb None None {'model/_target_': 'src.models.lf_module.LFLitModule', 'model/optimizer/_target_': 'torch.optim.AdamW', 'model/optimizer/_partial_': True, 'model/optimizer/lr': 0.01, 'model/optimizer/weight_decay': 0.0, 'model/scheduler/_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'model/scheduler/_partial_': True, 'model/scheduler/mode': 'min', 'model/scheduler/factor': 0.1, 'model/scheduler/patience': 10, 'model/net/_target_': 'src.models.recurrent.ssm.SSM', 'model/net/rec1_size': 16, 'model/net/return_sequences': True, 'model/net/dt': 1.0, 'model/net/activation': 'tanh', 'model/encoder/_target_': 'src.models.encoders.linear.Linear', 'model/encoder/in_size': 1, 'model/encoder/out_size': '${model.net.rec1_size}', 'model/decoder/_target_': 'src.models.decoders.linear.Linear', 'model/decoder/in_size': '${model.net.rec1_size}', 'model/decoder/out_size': 1, 'model/params/total': 1409, 'model/params/trainable': 1409, 'model/params/non_trainable': 0, 'data/_target_': 'src.data.lf_datamodule.LFDataModule', 'data/data_dir': '${paths.data_dir}', 'data/batch_size': 512, 'data/seq_length': 100, 'data/input_dim': 1, 'data/train_val_test_split': [128000, 12800, 12800], 'data/num_workers': 1, 'data/pin_memory': False, 'data/rho_name': 'pol', 'trainer/_target_': 'lightning.pytorch.trainer.Trainer', 'trainer/default_root_dir': '${paths.output_dir}', 'trainer/min_epochs': 2, 'trainer/max_epochs': 1000, 'trainer/accelerator': 'gpu', 'trainer/devices': 1, 'trainer/check_val_every_n_epoch': 1, 'trainer/deterministic': False, 'trainer/precision': 64, 'trainer/gradient_clip_val': 0.5, 'callbacks/model_checkpoint/_target_': 'lightning.pytorch.callbacks.ModelCheckpoint', 'callbacks/model_checkpoint/dirpath': '${paths.output_dir}/checkpoints', 'callbacks/model_checkpoint/filename': 'epoch_{epoch:03d}', 'callbacks/model_checkpoint/monitor': 'val/loss', 'callbacks/model_checkpoint/verbose': False, 'callbacks/model_checkpoint/save_last': True, 'callbacks/model_checkpoint/save_top_k': 2, 'callbacks/model_checkpoint/mode': 'min', 'callbacks/model_checkpoint/auto_insert_metric_name': False, 'callbacks/model_checkpoint/save_weights_only': False, 'callbacks/model_checkpoint/every_n_train_steps': None, 'callbacks/model_checkpoint/train_time_interval': None, 'callbacks/model_checkpoint/every_n_epochs': None, 'callbacks/model_checkpoint/save_on_train_epoch_end': None, 'callbacks/early_stopping/_target_': 'lightning.pytorch.callbacks.EarlyStopping', 'callbacks/early_stopping/monitor': 'val/loss', 'callbacks/early_stopping/min_delta': 0.0, 'callbacks/early_stopping/patience': 1000, 'callbacks/early_stopping/verbose': True, 'callbacks/early_stopping/mode': 'min', 'callbacks/early_stopping/strict': True, 'callbacks/early_stopping/check_finite': True, 'callbacks/early_stopping/stopping_threshold': 0.33520305156707764, 'callbacks/early_stopping/divergence_threshold': None, 'callbacks/early_stopping/check_on_train_epoch_end': None, 'callbacks/model_summary/_target_': 'lightning.pytorch.callbacks.RichModelSummary', 'callbacks/model_summary/max_depth': -1, 'callbacks/rich_progress_bar/_target_': 'lightning.pytorch.callbacks.RichProgressBar', 'callbacks/gradient_norms/_target_': 'src.callbacks.norms.TrackNorms', 'extras/ignore_warnings': False, 'extras/enforce_tags': True, 'extras/print_config': True, 'task_name': 'LF_tanh_ssm_pol', 'tags': ['lf', 'ssm'], 'ckpt_path': None, 'seed': 12345}
2023-09-04 21:50:12,075 INFO    MainThread:1460736 [wandb_run.py:_finish():1894] finishing run sanderwang/Curse-of-memory/li5gxo2h
2023-09-04 21:50:12,075 INFO    MainThread:1460736 [wandb_run.py:_atexit_cleanup():2128] got exitcode: 0
2023-09-04 21:50:12,075 INFO    MainThread:1460736 [wandb_run.py:_restore():2111] restore
2023-09-04 21:50:12,075 INFO    MainThread:1460736 [wandb_run.py:_restore():2117] restore done
2023-09-04 21:50:21,241 INFO    MainThread:1460736 [wandb_run.py:_footer_history_summary_info():3481] rendering history
2023-09-04 21:50:21,242 INFO    MainThread:1460736 [wandb_run.py:_footer_history_summary_info():3513] rendering summary
2023-09-04 21:50:21,247 INFO    MainThread:1460736 [wandb_run.py:_footer_sync_info():3440] logging synced files
