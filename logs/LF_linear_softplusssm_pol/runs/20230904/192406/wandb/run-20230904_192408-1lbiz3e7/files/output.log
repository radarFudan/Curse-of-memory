[[36m2023-09-04 19:24:14,059[39m][[34m__main__[39m][[32mINFO[39m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[[36m2023-09-04 19:24:14,166[39m][[34m__main__[39m][[32mINFO[39m] - Logging hyperparameters!
Running validation before training
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
In lf_datamodule.py, self.rho_name pol
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m      Validate metric      [22mâ”ƒ[1m       DataLoader 0        [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m         val/loss          [39mâ”‚[35m    15.359134674072266     [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m25/25[39m [37m0:00:01 â€¢ 0:00:00[39m [37m38.03it/s
[?25h[[36m2023-09-04 19:24:25,655[39m][[34m__main__[39m][[32mINFO[39m] - Starting training!
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name               [22mâ”ƒ[1m Type                  [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                â”‚ SoftplusSSM           â”‚ 20.8 K â”‚
â”‚ 1  â”‚ net.activation     â”‚ Identity              â”‚      0 â”‚
â”‚ 2  â”‚ net.W              â”‚ CustomLinearLayer     â”‚     64 â”‚
â”‚ 3  â”‚ net.P              â”‚ CustomOrthogonalLayer â”‚  4.1 K â”‚
â”‚ 4  â”‚ net.g              â”‚ MLP                   â”‚  8.3 K â”‚
â”‚ 5  â”‚ net.g.activation   â”‚ Identity              â”‚      0 â”‚
â”‚ 6  â”‚ net.g.linear1      â”‚ Linear                â”‚  4.2 K â”‚
â”‚ 7  â”‚ net.g.linear2      â”‚ Linear                â”‚  4.2 K â”‚
â”‚ 8  â”‚ net.f              â”‚ MLP                   â”‚  8.3 K â”‚
â”‚ 9  â”‚ net.f.activation   â”‚ Identity              â”‚      0 â”‚
â”‚ 10 â”‚ net.f.linear1      â”‚ Linear                â”‚  4.2 K â”‚
â”‚ 11 â”‚ net.f.linear2      â”‚ Linear                â”‚  4.2 K â”‚
â”‚ 12 â”‚ encoder            â”‚ Linear                â”‚    128 â”‚
â”‚ 13 â”‚ encoder.U          â”‚ Linear                â”‚    128 â”‚
â”‚ 14 â”‚ encoder.activation â”‚ Identity              â”‚      0 â”‚
â”‚ 15 â”‚ decoder            â”‚ Linear                â”‚     65 â”‚
â”‚ 16 â”‚ decoder.U          â”‚ Linear                â”‚     65 â”‚
â”‚ 17 â”‚ decoder.activation â”‚ Identity              â”‚      0 â”‚
â”‚ 18 â”‚ train_loss         â”‚ MeanMetric            â”‚      0 â”‚
â”‚ 19 â”‚ val_loss           â”‚ MeanMetric            â”‚      0 â”‚
â”‚ 20 â”‚ test_loss          â”‚ MeanMetric            â”‚      0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 21.0 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 21.0 K
[1mTotal estimated model params size (MB)[22m: 0
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning:
The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers`
argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(




















[37mEpoch 0/999[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:42 â€¢ 0:00:00[39m [37m5.86it/s [39m [37mv_num: z3e7 train/loss: 0.123 
[37mValidation[39m  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m16/25  [39m [37m0:00:00 â€¢ 0:00:01[39m [37m37.36it/s





















Epoch 2/999 [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m2/250[39m [37m0:00:00 â€¢ 0:00:42[39m [37m6.04it/s[39m [37mv_num: z3e7 train/loss: 0.029 val/loss: 0.039 



















Epoch 2/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:38 â€¢ 0:00:00[39m [37m6.65it/s[39m [37mv_num: z3e7 train/loss: 0.007 val/loss: 0.039 














Epoch 4/999 [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m2/250[39m [37m0:00:00 â€¢ 0:00:26[39m [37m9.65it/s[39m [37mv_num: z3e7 train/loss: 0.007 val/loss: 0.009 






















Epoch 4/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:45 â€¢ 0:00:00[39m [37m5.22it/s [39m [37mv_num: z3e7 train/loss: 0.008 val/loss: 0.009 























Epoch 5/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:47 â€¢ 0:00:00[39m [37m5.21it/s [39m [37mv_num: z3e7 train/loss: 38352967434240.0 val/loss: 
                                                                                         [37m0.014                                              























Epoch 6/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:47 â€¢ 0:00:00[39m [37m5.27it/s[39m [37mv_num: z3e7 train/loss: 0.009 val/loss: 0.523 
[37mValidation[39m  [35mâ”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m1/25   [39m [37m0:00:00 â€¢ -:--:--[39m [37m0.00it/s














































Epoch 8/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:45 â€¢ 0:00:00[39m [37m5.47it/s [39m [37mv_num: z3e7 train/loss: 0.012 val/loss: 0.013 
[37mValidation[39m  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”[39m [37m23/25  [39m [37m0:00:00 â€¢ 0:00:01[39m [37m32.57it/s






















Epoch 9/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:45 â€¢ 0:00:00[39m [37m5.47it/s [39m [37mv_num: z3e7 train/loss: 0.008 val/loss: 0.003 


















































Epoch 12/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•º[39m [37m246/250[39m [37m0:00:25 â€¢ 0:00:01[39m [37m9.73it/s[39m [37mv_num: z3e7 train/loss: 0.005 val/loss: 0.006 



























Epoch 15/999 [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m2/250[39m [37m0:00:00 â€¢ 0:00:29[39m [37m8.64it/s[39m [37mv_num: z3e7 train/loss: 0.006 val/loss: 0.002 
















































































Epoch 18/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:45 â€¢ 0:00:00[39m [37m5.40it/s [39m [37mv_num: z3e7 train/loss: 0.005 val/loss: 0.003 





































































Epoch 21/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:45 â€¢ 0:00:00[39m [37m5.45it/s [39m [37mv_num: z3e7 train/loss: 0.006 val/loss: 0.006 














































Epoch 23/999 [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m250/250[39m [37m0:00:45 â€¢ 0:00:00[39m [37m5.43it/s[39m [37mv_num: z3e7 train/loss: 0.002 val/loss: 0.002 
[?25h[[36m2023-09-04 19:40:52,180[39m][[34m__main__[39m][[32mINFO[39m] - Starting testing!
Stopping threshold reached: val/loss = 0.0016485347878187895 < 0.001670744619332254. Signaling Trainer to stop.
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
[37mValidation[39m [35mâ”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m5/25[39m [37m0:00:00 â€¢ 0:00:01[39m [37m34.35it/s
Restoring states from the checkpoint path at /home/shida/Figure_1/logs/LF_linear_softplusssm_pol/runs/20230904/192406/checkpoints/epoch_023.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m      Validate metric      [22mâ”ƒ[1m       DataLoader 0        [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m         val/loss          [39mâ”‚[35m   0.0016485347878187895   [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m25/25[39m [37m0:00:00 â€¢ 0:00:00[39m [37m36.44it/s
[?25hLF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m11/25[39m [37m0:00:00 â€¢ 0:00:01[39m [37m33.20it/s
Restoring states from the checkpoint path at /home/shida/Figure_1/logs/LF_linear_softplusssm_pol/runs/20230904/192406/checkpoints/epoch_023.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
Loaded model weights from the checkpoint at /home/shida/Figure_1/logs/LF_linear_softplusssm_pol/runs/20230904/192406/checkpoints/epoch_023.ckpt
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m        Test metric        [22mâ”ƒ[1m       DataLoader 0        [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m         test/loss         [39mâ”‚[35m   0.0016122421948239207   [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m25/25[39m [37m0:00:00 â€¢ 0:00:00[39m [37m34.49it/s
[?25h[[36m2023-09-04 19:41:17,156[39m][[34m__main__[39m][[32mINFO[39m] - Best ckpt path: /home/shida/Figure_1/logs/LF_linear_softplusssm_pol/runs/20230904/192406/checkpoints/epoch_023.ckpt
[[36m2023-09-04 19:41:17,157[39m][[34msrc.utils.utils[39m][[32mINFO[39m] - Output dir: /home/shida/Figure_1/logs/LF_linear_softplusssm_pol/runs/20230904/192406
[[36m2023-09-04 19:41:17,158[39m][[34msrc.utils.utils[39m][[32mINFO[39m] - Closing wandb!