[[36m2023-09-04 19:16:41,965[39m][[34m__main__[39m][[32mINFO[39m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[[36m2023-09-04 19:16:42,041[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[[36m2023-09-04 19:16:42,048[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - GPU available: True (cuda), used: True
[[36m2023-09-04 19:16:42,048[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - TPU available: False, using: 0 TPU cores
[[36m2023-09-04 19:16:42,049[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - IPU available: False, using: 0 IPUs
[[36m2023-09-04 19:16:42,049[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - HPU available: False, using: 0 HPUs
[[36m2023-09-04 19:16:42,049[39m][[34m__main__[39m][[32mINFO[39m] - Logging hyperparameters!
Running validation before training
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
In lf_datamodule.py, self.rho_name pol
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
[[36m2023-09-04 19:16:48,431[39m][[34msrc.models.recurrent.s4[39m][[32mINFO[39m] - S4: Initializing kernel to length 100
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m      Validate metric      [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         val/loss          [39m│[35m     15.2501859664917      [39m│
└───────────────────────────┴───────────────────────────┘
[37mValidation[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m25/25[39m [37m0:00:03 • 0:00:00[39m [37m55.96it/s
[?25h[[36m2023-09-04 19:16:49,297[39m][[34m__main__[39m][[32mINFO[39m] - Starting training!
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃[1m    [22m┃[1m Name                  [22m┃[1m Type          [22m┃[1m Params [22m┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                   │ S4Block       │ 20.7 K │
│ 1  │ net.layer             │ FFTConv       │ 16.5 K │
│ 2  │ net.layer.activation  │ GELU          │      0 │
│ 3  │ net.layer.kernel      │ SSMKernelDPLR │ 16.4 K │
│ 4  │ net.layer.drop        │ Identity      │      0 │
│ 5  │ net.layer.drop_kernel │ Identity      │      0 │
│ 6  │ net.mult_activation   │ Identity      │      0 │
│ 7  │ net.drop              │ Identity      │      0 │
│ 8  │ net.output_linear     │ Sequential    │  4.2 K │
│ 9  │ net.output_linear.0   │ Linear        │  4.2 K │
│ 10 │ net.output_linear.1   │ Identity      │      0 │
│ 11 │ encoder               │ Linear        │    128 │
│ 12 │ encoder.U             │ Linear        │    128 │
│ 13 │ encoder.activation    │ Identity      │      0 │
│ 14 │ decoder               │ Linear        │     65 │
│ 15 │ decoder.U             │ Linear        │     65 │
│ 16 │ decoder.activation    │ Identity      │      0 │
│ 17 │ train_loss            │ MeanMetric    │      0 │
│ 18 │ val_loss              │ MeanMetric    │      0 │
│ 19 │ test_loss             │ MeanMetric    │      0 │
└────┴───────────────────────┴───────────────┴────────┘
[1mTrainable params[22m: 20.9 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 20.9 K
[1mTotal estimated model params size (MB)[22m: 0
[37mSanity Checking[39m [35m━━━━━━━━━━━━━━━━━━━━[90m╺━━━━━━━━━━━━━━━━━━━[39m [37m1/2[39m [37m0:00:00 • -:--:--[39m [37m0.00it/s
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning:
The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers`
argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(




[37mEpoch 0/999[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[90m━[39m [37m241/250[39m [37m0:00:10 • 0:00:01[39m [37m23.95it/s[39m [37mv_num: 9hxt train/loss: 0.271 






Epoch 2/999 [35m━[90m╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m8/250[39m [37m0:00:00 • 0:00:11[39m [37m24.11it/s[39m [37mv_num: 9hxt train/loss: 0.046 val/loss: 0.079 






Epoch 3/999 [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m0/250[39m [37m0:00:11 • 0:00:00[39m [37m0.00it/s[39m [37mv_num: 9hxt train/loss: 0.02 val/loss: 0.041 







Epoch 3/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[39m [37m247/250[39m [37m0:00:14 • 0:00:01[39m [37m17.35it/s[39m [37mv_num: 9hxt train/loss: 0.028 val/loss: 0.041 







Epoch 4/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m250/250[39m [37m0:00:14 • 0:00:00[39m [37m17.98it/s[39m [37mv_num: 9hxt train/loss: 0.015 val/loss: 0.021 
[37mValidation[39m  [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[90m━━━━━━[39m [37m21/25  [39m [37m0:00:00 • 0:00:01[39m [37m31.67it/s







Epoch 5/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[90m━[39m [37m242/250[39m [37m0:00:13 • 0:00:01[39m [37m17.76it/s[39m [37mv_num: 9hxt train/loss: 0.017 val/loss: 0.014 







Epoch 6/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m250/250[39m [37m0:00:13 • 0:00:00[39m [37m18.24it/s[39m [37mv_num: 9hxt train/loss: 0.002 val/loss: 0.009 


















Epoch 10/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[90m━[39m [37m243/250[39m [37m0:00:08 • 0:00:01[39m [37m27.78it/s[39m [37mv_num: 9hxt train/loss: 0.006 val/loss: 0.165 















Epoch 12/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[39m [37m248/250[39m [37m0:00:14 • 0:00:01[39m [37m16.91it/s[39m [37mv_num: 9hxt train/loss: 0.002 val/loss: 0.017 







Epoch 13/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m250/250[39m [37m0:00:15 • 0:00:00[39m [37m16.74it/s[39m [37mv_num: 9hxt train/loss: 0.002 val/loss: 0.003 








Epoch 15/999 [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m0/250[39m [37m0:00:14 • 0:00:00[39m [37m0.00it/s[39m [37mv_num: 9hxt train/loss: 0.007 val/loss: 0.002 






















Epoch 17/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m250/250[39m [37m0:00:14 • 0:00:00[39m [37m17.09it/s[39m [37mv_num: 9hxt train/loss: 0.001 val/loss: 0.005 







Epoch 18/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[39m [37m247/250[39m [37m0:00:13 • 0:00:01[39m [37m18.18it/s[39m [37mv_num: 9hxt train/loss: 0.001 val/loss: 0.006 
Epoch 18/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m250/250[39m [37m0:00:13 • 0:00:00[39m [37m18.15it/s[39m [37mv_num: 9hxt train/loss: 0.005 val/loss: 0.002 
[?25h[[36m2023-09-04 19:22:01,906[39m][[34m__main__[39m][[32mINFO[39m] - Starting testing!
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
[[36m2023-09-04 19:22:03,046[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - Restoring states from the checkpoint path at /home/shida/Figure_1/logs/LF_linear_s4_pol/runs/20230904/191635/checkpoints/epoch_018.ckpt
[[36m2023-09-04 19:22:03,156[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - Loaded model weights from the checkpoint at /home/shida/Figure_1/logs/LF_linear_s4_pol/runs/20230904/191635/checkpoints/epoch_018.ckpt
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m      Validate metric      [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         val/loss          [39m│[35m   0.0016225854633376002   [39m│
└───────────────────────────┴───────────────────────────┘
[37mValidation[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m25/25[39m [37m0:00:00 • 0:00:00[39m [37m35.16it/s
[?25h
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[?25hLF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
[[36m2023-09-04 19:22:05,255[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - Restoring states from the checkpoint path at /home/shida/Figure_1/logs/LF_linear_s4_pol/runs/20230904/191635/checkpoints/epoch_018.ckpt
[[36m2023-09-04 19:22:05,347[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - Loaded model weights from the checkpoint at /home/shida/Figure_1/logs/LF_linear_s4_pol/runs/20230904/191635/checkpoints/epoch_018.ckpt
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m        Test metric        [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         test/loss         [39m│[35m   0.0015976225258782506   [39m│
└───────────────────────────┴───────────────────────────┘
[37mTesting[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m25/25[39m [37m0:00:00 • 0:00:00[39m [37m34.97it/s
[?25h[[36m2023-09-04 19:22:06,354[39m][[34m__main__[39m][[32mINFO[39m] - Best ckpt path: /home/shida/Figure_1/logs/LF_linear_s4_pol/runs/20230904/191635/checkpoints/epoch_018.ckpt
[[36m2023-09-04 19:22:06,356[39m][[34msrc.utils.utils[39m][[32mINFO[39m] - Output dir: /home/shida/Figure_1/logs/LF_linear_s4_pol/runs/20230904/191635
[[36m2023-09-04 19:22:06,356[39m][[34msrc.utils.utils[39m][[32mINFO[39m] - Closing wandb!