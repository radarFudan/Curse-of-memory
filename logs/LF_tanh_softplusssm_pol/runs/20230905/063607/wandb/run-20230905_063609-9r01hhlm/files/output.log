[[36m2023-09-05 06:36:14,178[39m][[34m__main__[39m][[32mINFO[39m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[[36m2023-09-05 06:36:14,266[39m][[34m__main__[39m][[32mINFO[39m] - Logging hyperparameters!
Running validation before training
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
In lf_datamodule.py, self.rho_name pol
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m      Validate metric      [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         val/loss          [39m│[35m    15.181711196899414     [39m│
└───────────────────────────┴───────────────────────────┘
[37mValidation[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m25/25[39m [37m0:00:01 • 0:00:00[39m [37m57.84it/s
[?25h[[36m2023-09-05 06:36:18,918[39m][[34m__main__[39m][[32mINFO[39m] - Starting training!
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
┏━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃[1m    [22m┃[1m Name               [22m┃[1m Type                  [22m┃[1m Params [22m┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ net                │ SoftplusSSM           │ 20.8 K │
│ 1  │ net.W              │ CustomLinearLayer     │     64 │
│ 2  │ net.P              │ CustomOrthogonalLayer │  4.1 K │
│ 3  │ net.g              │ MLP                   │  8.3 K │
│ 4  │ net.g.linear1      │ Linear                │  4.2 K │
│ 5  │ net.g.linear2      │ Linear                │  4.2 K │
│ 6  │ net.f              │ MLP                   │  8.3 K │
│ 7  │ net.f.linear1      │ Linear                │  4.2 K │
│ 8  │ net.f.linear2      │ Linear                │  4.2 K │
│ 9  │ encoder            │ Linear                │    128 │
│ 10 │ encoder.U          │ Linear                │    128 │
│ 11 │ encoder.activation │ Identity              │      0 │
│ 12 │ decoder            │ Linear                │     65 │
│ 13 │ decoder.U          │ Linear                │     65 │
│ 14 │ decoder.activation │ Identity              │      0 │
│ 15 │ train_loss         │ MeanMetric            │      0 │
│ 16 │ val_loss           │ MeanMetric            │      0 │
│ 17 │ test_loss          │ MeanMetric            │      0 │
└────┴────────────────────┴───────────────────────┴────────┘
[1mTrainable params[22m: 21.0 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 21.0 K
[1mTotal estimated model params size (MB)[22m: 0
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430:
PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider
increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the
`DataLoader` init to improve performance.
  rank_zero_warn(












[37mEpoch 0/999[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m250/250[39m [37m0:00:26 • 0:00:00[39m [37m9.63it/s[39m [37mv_num: hhlm train/loss: 1.124 
Epoch 1/999 [35m━[90m╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m7/250[39m [37m0:00:00 • 0:00:26[39m [37m9.66it/s[39m [37mv_num: hhlm train/loss: 3.056         


                                                                                    [37mval/loss: 1.158                     










                                                                                    [37mval/loss: 0.487                     


Epoch 5/999 [35m━━━━━━━━━━━━[90m╺━━━━━━━━━━━━━━━━━━━━━━━[39m [37m86/250[39m [37m0:00:08 • 0:00:17[39m [37m9.81it/s[39m [37mv_num: hhlm train/loss: 0.247        

                                                                                    [37mval/loss: 0.247                     



                                                                                    [37mval/loss: 0.128                     
[37mValidation[39m  [35m━━━━━━━━━━━━━━━━━━━━━━[90m╺━━━━━━━━━━━━[39m [37m16/25  [39m [37m0:00:00 • 0:00:01[39m [37m51.94it/s












                                                                                    [37mval/loss: 0.118                     


                                                                                    [37mval/loss: 0.066                     


Epoch 13/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸[90m━[39m [37m242/250[39m [37m0:00:24 • 0:00:01[39m [37m9.99it/s[39m [37mv_num: hhlm train/loss: 0.132       



Epoch 14/999 [35m━━━━━━━━━━━━━━━━━━━━━━╸[90m━━━━━━━━━━━━[39m [37m163/250[39m [37m0:00:16 • 0:00:09[39m [37m9.94it/s[39m [37mv_num: hhlm train/loss: 0.067       




Epoch 16/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[90m╺━━━━━━[39m [37m200/250[39m [37m0:00:20 • 0:00:06[39m [37m9.82it/s[39m [37mv_num: hhlm train/loss: 0.116       



Epoch 17/999 [35m━━━━━━━━━━━━━━━━━[90m╺━━━━━━━━━━━━━━━━━[39m [37m122/250[39m [37m0:00:12 • 0:00:13[39m [37m9.96it/s[39m [37mv_num: hhlm train/loss: 0.344       


                                                                                    [37mval/loss: 0.088                     
Epoch 18/999 [35m━━━━━╸[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m42/250[39m [37m0:00:04 • 0:00:21[39m [37m10.04it/s[39m [37mv_num: hhlm train/loss: 0.076       





Epoch 20/999 [35m━━━━━━━━╸[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m60/250[39m [37m0:00:06 • 0:00:20[39m [37m9.90it/s[39m [37mv_num: hhlm train/loss: 0.076       




                                                                                    [37mval/loss: 0.144                     




Epoch 24/999 [35m━━━━━━━━━━━━━╸[90m━━━━━━━━━━━━━━━━━━━━━[39m [37m97/250[39m [37m0:00:09 • 0:00:16[39m [37m10.00it/s[39m [37mv_num: hhlm train/loss: 0.012       

                                                                                    [37mval/loss: 0.138                     
Stopping threshold reached: val/loss = 0.009606484323740005 < 0.03714309260249138. Signaling Trainer to stop.
Restoring states from the checkpoint path at /home/shida/Figure_1/logs/LF_tanh_softplusssm_pol/runs/20230905/063607/checkpoints/epoch_024.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
Loaded model weights from the checkpoint at /home/shida/Figure_1/logs/LF_tanh_softplusssm_pol/runs/20230905/063607/checkpoints/epoch_024.ckpt
Epoch 24/999 [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m250/250[39m [37m0:00:25 • 0:00:00[39m [37m9.91it/s[39m [37mv_num: hhlm train/loss: 0.009       
                                                                                    [37mval/loss: 0.01                      
[?25h[[36m2023-09-05 06:47:15,493[39m][[34m__main__[39m][[32mINFO[39m] - Starting testing!
LF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
[37mValidation[39m [35m━━━━━━[90m╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m4/25[39m [37m0:00:00 • 0:00:01[39m [37m53.69it/s
Restoring states from the checkpoint path at /home/shida/Figure_1/logs/LF_tanh_softplusssm_pol/runs/20230905/063607/checkpoints/epoch_024.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m      Validate metric      [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         val/loss          [39m│[35m   0.009606484323740005    [39m│
└───────────────────────────┴───────────────────────────┘
[37mValidation[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m25/25[39m [37m0:00:00 • 0:00:00[39m [37m57.05it/s
[?25hLF_generate done
In lf datagen, input shape (153600, 100, 1)
In lf datagen, output shape (153600, 100, 1)
[?25l
/home/shida/anaconda3/envs/lh/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m        Test metric        [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         test/loss         [39m│[35m   0.009962132200598717    [39m│
└───────────────────────────┴───────────────────────────┘
[37mTesting[39m [35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m25/25[39m [37m0:00:00 • 0:00:00[39m [37m60.66it/s
[?25h[[36m2023-09-05 06:47:19,766[39m][[34m__main__[39m][[32mINFO[39m] - Best ckpt path: /home/shida/Figure_1/logs/LF_tanh_softplusssm_pol/runs/20230905/063607/checkpoints/epoch_024.ckpt
[[36m2023-09-05 06:47:19,768[39m][[34msrc.utils.utils[39m][[32mINFO[39m] - Output dir: /home/shida/Figure_1/logs/LF_tanh_softplusssm_pol/runs/20230905/063607
[[36m2023-09-05 06:47:19,768[39m][[34msrc.utils.utils[39m][[32mINFO[39m] - Closing wandb!